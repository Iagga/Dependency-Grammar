{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Grammar (first assignment NLU)\n",
    "* Gaia Trebucchi\n",
    "* Gaia.trebucchi@gmail.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "sentence='I saw the man with the telescope.'\n",
    "sentence1='Gaia brought her cat Costina some delicious food'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1:\n",
    "#### Extract a path of dependency relations from the ROOT to a token. \n",
    "This function takes as input a sentence and return a dictionary whose keys are the tokens of the sentence and the value for each keys is a list, representing the token we encounter from the root of the sentence to the token stored as the key. Each element of the list is a tuple composed by a token and the dependency relation with his head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_dependency(sentence):\n",
    "    doc=spacy_nlp(sentence)\n",
    "    list_path=dict()\n",
    "    for token in doc:\n",
    "        dep_path=[(token,token.dep_)]\n",
    "        index=token.i\n",
    "        while doc[index].dep_!='ROOT':\n",
    "            index=doc[index].head.i\n",
    "            dep_path.append((doc[index],doc[index].dep_))\n",
    "        path=dep_path[::-1]\n",
    "        list_path[token]=path\n",
    "    return list_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with the sentence \"I saw the man with the telescope\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{I: [(saw, 'ROOT'), (I, 'nsubj')], saw: [(saw, 'ROOT')], the: [(saw, 'ROOT'), (man, 'dobj'), (the, 'det')], man: [(saw, 'ROOT'), (man, 'dobj')], with: [(saw, 'ROOT'), (man, 'dobj'), (with, 'prep')], the: [(saw, 'ROOT'), (man, 'dobj'), (with, 'prep'), (telescope, 'pobj'), (the, 'det')], telescope: [(saw, 'ROOT'), (man, 'dobj'), (with, 'prep'), (telescope, 'pobj')], .: [(saw, 'ROOT'), (., 'punct')]}\n"
     ]
    }
   ],
   "source": [
    "print(path_dependency(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuction 2:\n",
    "#### Extract subtree of a dependents given a token.\n",
    "The input of this function is a sentence and the output is a dictionary whose keys are the tokens of the sentence and whose value for each key is the list of tokens (as strings) belonging to the subtree of the token stored as a key, in the order they appear in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_token(sentence):\n",
    "    doc=spacy_nlp(sentence)\n",
    "    sub_token=dict()\n",
    "    for token in doc:\n",
    "        depend=[]\n",
    "        sub=token.subtree\n",
    "        for t in sub:\n",
    "            depend.append(t)\n",
    "        sub_token[token]=depend\n",
    "    return sub_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with the sentence \"I saw the man with the telescope\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{I: [I], saw: [I, saw, the, man, with, the, telescope, .], the: [the], man: [the, man, with, the, telescope], with: [with, the, telescope], the: [the], telescope: [the, telescope], .: [.]}\n"
     ]
    }
   ],
   "source": [
    "print(subtree_token(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3:\n",
    "#### check if a given list of tokens (segment of a sentence) forms a subtree.\n",
    "This function takes as input a sentence and a segment of the sentence and returns as output True if the segment forms a subtree of dependencies in the sentence and False if it doesn't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_subtree(sentence,segment):\n",
    "    sub_tree=subtree_token(sentence)\n",
    "    for value in sub_tree.values():\n",
    "        text_list=[]\n",
    "        for token in value:\n",
    "            text_list.append(token.text)\n",
    "        if text_list==segment:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with two different segments (one that forms a subtree of dependencies in the input sentence parsing and one that doesn't) and the sentence \"I saw the man with the telescope\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_subtree(sentence,[ 'the', 'telescope', 'with']))\n",
    "print(check_subtree(sentence,[ 'the', 'man','with','the', 'telescope']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 4:\n",
    "#### identify head of a span, given its tokens.\n",
    "The input of this function is a list of tokens (not necessarily a sentence) and the output is the head of the span of the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_of_span(segment):\n",
    "    seg=segment[0]\n",
    "    for i in range(1,len(segment)):\n",
    "        seg+=\" \"+segment[i]\n",
    "    doc=spacy_nlp(seg)\n",
    "    span=doc[:]\n",
    "    return span.root\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with different lists of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man\n",
      "saw\n",
      "chance\n"
     ]
    }
   ],
   "source": [
    "print(head_of_span(['the', 'man','with','the','telescope']))\n",
    "print(head_of_span(['I','saw','you','last','week']))\n",
    "print(head_of_span(['last','chance','for','you']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 5:\n",
    "#### extract sentence subject, direct object and indirect object spans.\n",
    "This function takes as input a sentence and return a dictionary whose keys are tuples consisting of the token and its dependency relation (nsubj for the subject, dobj for the direct object and dative for the indirect object) and the value for each key is the span of the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans(sentence):\n",
    "    doc=spacy_nlp(sentence)\n",
    "    spans_dict=dict()\n",
    "    for token in doc:\n",
    "        if token.dep_=='nsubj' or token.dep_==\"dobj\" or token.dep_==\"dative\":\n",
    "            index=token.i\n",
    "            span=doc[doc[index].left_edge.i : doc[index].right_edge.i+1]\n",
    "            spans_dict[(token,token.dep_)]=span\n",
    "    return spans_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with the two sentences: \"I saw the man with the telescope\", \"Gaia brought her cat Costina some delicious food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(I, 'nsubj'): I, (man, 'dobj'): the man with the telescope}\n",
      "{(Gaia, 'nsubj'): Gaia, (Costina, 'dative'): her cat Costina, (food, 'dobj'): some delicious food}\n"
     ]
    }
   ],
   "source": [
    "print(get_spans(sentence))\n",
    "print(get_spans(sentence1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
